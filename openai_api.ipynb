{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602b088",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3532551931.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install python-dotenv\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#키 관리를 위한 .env 사용\n",
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb5b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenvNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bfdf369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "#키 가져오기\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca8a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.93.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp39-cp39-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in .\\.venv\\lib\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in .\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.93.0-py3-none-any.whl (755 kB)\n",
      "   ---------------------------------------- 0.0/755.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 755.0/755.0 kB 15.9 MB/s eta 0:00:00\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp39-cp39-win_amd64.whl (208 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   ------ ---------------------------------  2/13 [sniffio]\n",
      "   --------------- ------------------------  5/13 [h11]\n",
      "   --------------- ------------------------  5/13 [h11]\n",
      "   --------------- ------------------------  5/13 [h11]\n",
      "   ------------------ ---------------------  6/13 [distro]\n",
      "   --------------------- ------------------  7/13 [annotated-types]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ---------------------------------------- 13/13 [openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.93.0 pydantic-2.11.7 pydantic-core-2.33.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1191039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "#OpenAI 객체 생성\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "#response 객체 생성\n",
    "response = client.responses.create(\n",
    "    #모델 설정\n",
    "    model='gpt-4.1',\n",
    "    #질문하기\n",
    "    input='스타워즈 시리즈의 다스베이더에 대해 한줄로 설명해줘'\n",
    ")\n",
    "#응답 출력\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5704504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다스 베이더는 스타워즈 시리즈에서 포스를 사용하는 강력한 시스 군주이자, 원래 제다이였던 아나킨 스카이워커의 타락한 모습입니다.\n"
     ]
    }
   ],
   "source": [
    "#응답 출력\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b96b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋은 질문이네! 오늘의 기분이나 특별히 땡기는 음식이 있을까?  \n",
      "아무 생각이 없다면, 몇 가지 옵션을 추천해줄게:\n",
      "\n",
      "1. **한식**  \n",
      "- 김치찌개+계란말이  \n",
      "- 불고기덮밥  \n",
      "- 비빔밥  \n",
      "\n",
      "2. **양식**  \n",
      "- 크림 파스타  \n",
      "- 마르게리타 피자  \n",
      "- 치킨 샐러드  \n",
      "\n",
      "3. **일식**  \n",
      "- 돈카츠 정식  \n",
      "- 연어덮밥  \n",
      "- 우동  \n",
      "\n",
      "4. **분식**  \n",
      "- 떡볶이+순대  \n",
      "- 김밥+오뎅  \n",
      "- 라면+계란  \n",
      "\n",
      "5. **중식**  \n",
      "- 짜장면  \n",
      "- 마파두부덮밥  \n",
      "- 탕수육  \n",
      "\n",
      "비 오는 날엔 따뜻한 국물 요리도 잘 어울리고, 날씨가 더우면 시원한 냉면이나 샐러드도 추천해!  \n",
      "혹시 재료를 가지고 있는 게 있다면 알려주면 그걸로 메뉴도 추천해줄 수 있어.  \n",
      "지금 어떤 분위기인지, 혹시 먹고 싶은 게 있는지도 더 말해줘! ✨\n"
     ]
    }
   ],
   "source": [
    "# response = client.responses.create(\n",
    "#     model='gpt-4.1',\n",
    "#     input=[ \n",
    "#         {\n",
    "#             'role': 'developer',\n",
    "#             'content': '음식에 대한 이야기 하는 것을 좋아해'\n",
    "#         },\n",
    "#         {\n",
    "#             'role': 'user',\n",
    "#             'content': '오늘은 무엇을 먹을까?'\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977cb939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스타워즈 시리즈는 은하계를 배경으로 선과 악의 세력, 제다이와 시스의 싸움을 그린 SF 판타지 영화 프랜차이즈입니다.\n"
     ]
    }
   ],
   "source": [
    "# completion = client.chat.completions.create(\n",
    "#     model='gpt-4.1',\n",
    "#     messages=[\n",
    "#         {\n",
    "#             'role': 'user',\n",
    "#             'content': '스타워즈 시리즈에 대해 한 문장으로 설명해줘'\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "344634d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finish_reason': 'stop',\n",
       " 'index': 0,\n",
       " 'logprobs': None,\n",
       " 'message': ChatCompletionMessage(content='스타워즈 시리즈는 은하계를 배경으로 제다이와 시스 간의 선과 악의 대결, 가족과 운명의 이야기를 그린 SF 영화 시리즈입니다.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict(completion.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75ad634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! How can I help you today? If you have a question or need assistance, just let me know.\n"
     ]
    }
   ],
   "source": [
    "# #input을 사용하여 콘솔에서 사용자 입력을 받고 응답 처리하는 프로그램\n",
    "# user_input = input('질문을 입력하세요: ')\n",
    "# response = client.responses.create(\n",
    "#     model='gpt-4.1',\n",
    "#     input=[ \n",
    "#           {\n",
    "#             'role': 'user',\n",
    "#             'content': user_input\n",
    "#         }\n",
    "#     ] \n",
    "# )\n",
    "# print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa647e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api 연동하여 데이터 가져오기\n",
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "634357b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools = [{ ... }] 여러 개의 함수 정의를 리스트로 묶어서 전달\n",
    "tools = [{\n",
    "    #함수 호출용 툴임을 명시, 만약 이미지를 생성하는 툴이면 \"type\": \"image\"처럼 다르게 표기\n",
    "    \"type\": \"function\",\n",
    "    #함수의 이름, 나중에 모델이 함수 호출 요청 시 \"get_weather\"라는 이름으로 호출\n",
    "    \"name\": \"get_weather\",\n",
    "    # description: 이 함수가 어떤 역할을 하는지 설명하는 텍스트, 모델이 함수 선택/이해 시 참고\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    #함수에 전달해야 할 파라미터(입력값) 정의\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"latitude\", \"longitude\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    #엄격하게 파라미터 형식이 맞는 경우에만 함수 호출을 허용, 위도/경도 중 하나라도 빠지면 함수 호출이 실행되지 않음\n",
    "    \"strict\": True\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79d1b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  [ResponseFunctionToolCall(arguments='{\"latitude\":48.8566,\"longitude\":2.3522}', call_id='call_LcbrgFOgA8S2ewhsN3Qu7DAE', name='get_weather', type='function_call', id='fc_685bb12c9ed0819ab4dd7b610cb55c3c0141531f9baaf652', status='completed')]\n"
     ]
    }
   ],
   "source": [
    "input_messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"}]\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print('1. ', response.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eca1c6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': '{\"latitude\":48.8566,\"longitude\":2.3522}',\n",
       " 'call_id': 'call_LcbrgFOgA8S2ewhsN3Qu7DAE',\n",
       " 'name': 'get_weather',\n",
       " 'type': 'function_call',\n",
       " 'id': 'fc_685bb12c9ed0819ab4dd7b610cb55c3c0141531f9baaf652',\n",
       " 'status': 'completed'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response.output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9045daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#call에 대한 응답 데이터\n",
    "tool_call = response.output[0]\n",
    "#json 형태로 반환\n",
    "args = json.loads(tool_call.arguments) #arguments': '{\"latitude\":48.8566,\"longitude\":2.3522}',\n",
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca17e277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Paris today is 23.2°C, which is quite pleasant and mild. If you need more details about conditions like rain, wind, or recommendations on what to wear, let me know!\n"
     ]
    }
   ],
   "source": [
    "input_messages.append(tool_call) # append model's function call message\n",
    "\n",
    "input_messages.append({\n",
    "    'type': 'function_call_output',\n",
    "    'call_id': tool_call.call_id,\n",
    "    'output': str(result)\n",
    "})\n",
    "\n",
    "#최종 응답\n",
    "response2 = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(response2.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수호출 하는 챗봇 구성\n",
    "#임의의 함수를 정의하고 설정해서 응답 메시지 결과에 반영이 되도록 정의\n",
    "#함수 정의와 툴 정의가 중요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f9036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과는 24 입니다.\n",
      "Response(id='resp_685bc38adf1c819bb02f777d8d8e1d450fb2d6e1a6727231', created_at=1750844298.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseFunctionToolCall(arguments='{\"birthday\":\"2001-04-06\"}', call_id='call_xf3weND1l3dgred2WjSlKF5I', name='calculate_age', type='function_call', id='fc_685bc38b33b4819b8225dd20a02793e30fb2d6e1a6727231', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='calculate_age', parameters={'type': 'object', 'properties': {'birthday': {'type': 'string'}}, 'required': ['birthday'], 'additionalProperties': False}, strict=True, type='function', description='생일을 입력받아 현재 나이를 계산한다.'), FunctionTool(name='convert_currency', parameters={'type': 'object', 'properties': {'amount': {'type': 'number'}}, 'required': ['amount'], 'additionalProperties': False}, strict=True, type='function', description='달러를 입력받아 원화로 변환한다.'), FunctionTool(name='calculate_bmi', parameters={'type': 'object', 'properties': {'height': {'type': 'number'}, 'weight': {'type': 'number'}}, 'required': ['height', 'weight'], 'additionalProperties': False}, strict=True, type='function', description='키와 몸무게를 입력받아 BMI를 계산한다.')], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=130, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=20, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=150), user=None, store=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from function_module import tools, calculate_age, calculate_bmi, convert_currency\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#키 가져오기\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "#OpenAI 객체 생성\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "input_messages = \"calculate_age 함수를 사용해서 내 나이를 계산해줘. 내 생일은 2001-04-06이야.\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "dict(response.output[0])\n",
    "#call에 대한 응답 데이터\n",
    "tool_call = response.output[0]\n",
    "#json형태로 변환\n",
    "args = json.loads(tool_call.arguments)\n",
    "\n",
    "#함수가 3개이기 때문에 name에 따라 다른 결과 반환하기\n",
    "tool_name = tool_call.name\n",
    "\n",
    "#나이 계산일 때\n",
    "if tool_name == 'calculate_age':\n",
    "    result = calculate_age(args['birthday'])\n",
    "#환율 계산일 때\n",
    "elif tool_name == 'convert_currency':\n",
    "    result = convert_currency(args['amount'])\n",
    "#BMI계산일 때\n",
    "elif tool_name == 'calulate_bmi':\n",
    "    result = calculate_bmi(args['height', 'weight'])\n",
    "#그 외(에러)\n",
    "else:\n",
    "    result = {'ERROR': '예정에 없는 함수 호출입니다.'}\n",
    "print(f'결과는 {result} 입니다.')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
